{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Summary\n",
    "#### There are many Machine Learning (ML) and Natural Language Processing (NLP) tools to explore. Here I will define several products and analysis goals to achieve with NLP.\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-cf1dfa70df75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "# from tensorflow.keras import layers\n",
    "# import nltk\n",
    "# from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import json\n",
    "from flask import Flask, jsonify, render_template\n",
    "from datetime import date\n",
    "\n",
    "\n",
    "import spacy\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywhatkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pywhatkit.text_to_handwriting(\"\"\"Test this library\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fpdf import FPDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin with FOTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data\n",
    "# Decision: read from a PDF or .txt file? The PDF may require extra data wrangling and cleanup, which is good, but the .txt can be had from Kaggle. Perhaps better practice from PDF.\n",
    "# Could use both at first to compare..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = os.path.join(\"data\", \"01 - The Fellowship Of The Ring.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\n",
    "    PATH, \"r\", encoding=\"ISO-8859-1\"\n",
    ") as file:  # changed encoding to deal with \"UnicodeDecodeError: 'utf-8' codec can't decode byte 0xf3 in position 2836: invalid continuation byte\" error\n",
    "    lotr_text = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment with TensorFlow and Keras\n",
    "#### Think about the end goal and then plot next steps... this might not be the path to go on since this is specific to the Character RNN exercise in the HOML text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = keras.preprocessing.text.Tokenizer(char_level=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts([lotr_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_id = len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = tokenizer.document_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[encoded] = np.array(tokenizer.texts_to_sequences([lotr_text])) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From news-sentiment-analysis-app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "stoplist = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get nGrams: (2, 2) for bigrams, (3, 3) for trigrams...\n",
    "vectorizer = CountVectorizer(\n",
    "    stop_words=stoplist, ngram_range=(3, 3)\n",
    ")  # Converts a collection of text documents to a matrix of token counts: the occurrences of tokens in each document. This implementation produces a sparse representation of the counts.\n",
    "X = vectorizer.fit_transform([lotr_text])\n",
    "features = vectorizer.get_feature_names()\n",
    "print(\"\\n\\nX : \\n\", X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting top ranking features\n",
    "sums = X.sum(axis=0)\n",
    "data = []\n",
    "for col, term in enumerate(features):\n",
    "    data.append((term, sums[0, col]))\n",
    "ranking = pd.DataFrame(data, columns=[\"phrase\", \"rank\"])\n",
    "words = ranking.sort_values(\"rank\", ascending=False)\n",
    "print(\"\\n\\nWords : \\n\", words.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select top 50 nGrams and add to new dataframe\n",
    "trigram_df = words.head(n=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = trigram_df\n",
    "term = df_data[\"phrase\"]\n",
    "frequency = df_data[\"rank\"]\n",
    "\n",
    "trace1 = {\n",
    "    \"x\": term,\n",
    "    \"y\": frequency,\n",
    "    \"mode\": \"markers\",\n",
    "    \"hovertemplate\": \"Trigram: %{x}<br>Count: %{y}<extra></extra>\",\n",
    "    \"marker\": {\n",
    "        \"color\": frequency,\n",
    "        \"size\": frequency,\n",
    "        \"sizeref\": 0.3,\n",
    "        \"sizemode\": \"area\",\n",
    "        \"opacity\": 1,\n",
    "    },\n",
    "}\n",
    "\n",
    "data_to_plot = [\n",
    "    trace1,\n",
    "]\n",
    "\n",
    "plot_layout = {\n",
    "    \"title\": \"Trigram frequency\",\n",
    "    \"autosize\": False,\n",
    "    \"height\": 700,\n",
    "    \"width\": 1200,\n",
    "    \"margin\": {\"l\": 50, \"r\": 50, \"b\": 200, \"t\": 100, \"pad\": 4},\n",
    "    \"xaxis\": {\n",
    "        \"title\": \"Trigrams\",\n",
    "        \"automargin\": True,\n",
    "        \"tickangle\": 45,\n",
    "        \"titlefont\": {\"family\": \"Arial, bold\", \"size\": 18, \"color\": \"black\"},\n",
    "    },\n",
    "    \"yaxis\": {\n",
    "        \"title\": \"Count\",\n",
    "        \"automargin\": True,\n",
    "        \"type\": \"log\",\n",
    "        \"titlefont\": {\"family\": \"Arial, sans-serif\", \"size\": 18, \"color\": \"black\"},\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data_to_plot, plot_layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.update_yaxes(type=\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python37964bitab8bbf6ad93b464ab4f574905cee7754"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
